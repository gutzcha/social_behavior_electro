{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cd4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af63149",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477dacf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Project- Electro\\\\social_behavior_electro\\\\data_organization\\\\python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b69cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = osp.join('..','..','analysis')\n",
    "path_to_aversive_enc_pre = osp.join(folder_path,\n",
    "                            'Population analysis results for LFP Coherence - Encounter-PreEncounter_4-12_30-80_aversive.xlsx')\n",
    "path_to_affiliative_enc_pre = osp.join(folder_path,\n",
    "                               'Population analysis results for LFP Coherence - Encounter-PreEncounter_4-12_30-80_affiliative.xlsx')\n",
    "\n",
    "path_to_aversive_post_pre = osp.join(folder_path,\n",
    "                            'Population analysis results for LFP Coherence - PostEncounter-PreEncounter_4-12_30-80_aversive.xlsx')\n",
    "path_to_affiliative_post_pre = osp.join(folder_path,\n",
    "                               'Population analysis results for LFP Coherence - PostEncounter-PreEncounter_4-12_30-80_affiliative.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "path_to_affiliative_lfp = osp.join(folder_path,\n",
    "                            'lfp_rawdata_affiliative.xlsx') \n",
    "\n",
    "path_to_aversive_lfp = osp.join(folder_path,\n",
    "                            'lfp_rawdata_aversive.xlsx')\n",
    "\n",
    "path_to_common_areas = osp.join(folder_path, 'common_area_pairs_w5_sessions.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b00eb446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aff_lfp_raw = pd.read_excel(path_to_affiliative_lfp ,header=[0,1,2], index_col=[0])\n",
    "df_avv_lfp_raw = pd.read_excel(path_to_aversive_lfp ,header=[0,1,2], index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9d461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4fabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aff_enc_pre = pd.read_excel(path_to_affiliative_enc_pre,None)\n",
    "df_avv_enc_pre = pd.read_excel(path_to_aversive_enc_pre,None)\n",
    "\n",
    "df_aff_post_pre = pd.read_excel(path_to_affiliative_post_pre,None)\n",
    "df_avv_post_pre = pd.read_excel(path_to_aversive_post_pre,None)\n",
    "\n",
    "\n",
    "df_files_avv_bad = pd.read_excel(path_to_aversive_enc_pre,'Uploaded files', header=None)\n",
    "df_files_aff_bad = pd.read_excel(path_to_affiliative_enc_pre,'Uploaded files', header=None)\n",
    "\n",
    "df_areas = pd.read_excel(path_to_common_areas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba353773",
   "metadata": {},
   "source": [
    "## Clean and combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6e2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def fix_file_paths(df_files):\n",
    "    \n",
    "    df_files = df_files.rename(columns={df_files.columns[0]:'timestamps', df_files.columns[0]:'lfp', })\n",
    "    \n",
    "    return df_files\n",
    "df_files_avv = fix_file_paths(df_files_avv_bad)['lfp']\n",
    "df_files_aff = fix_file_paths(df_files_aff_bad)['lfp']\n",
    "\n",
    "\n",
    "def extract_ratnum_from_file_name(filename):\n",
    "    filename = filename.replace(' ','')\n",
    "    match = re.search(r\"rat(\\d{1,2})\", filename.lower())\n",
    "\n",
    "    if match:\n",
    "        number = int(match.group(1))       \n",
    "    else:\n",
    "        number = -1\n",
    "    return number\n",
    "\n",
    "def extract_daynum_from_file_name(filename):\n",
    "    filename = filename.replace(' ','')\n",
    "    match = re.search(r\"day(\\d{1,2})\", filename.lower())\n",
    "    if match:\n",
    "        number = int(match.group(1))       \n",
    "    else:\n",
    "        number = -1\n",
    "    return number\n",
    "# rat_numbers = [extract_ratnum_from_file_name(filename) for filename in filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "616a1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_num_to_name_map = {\n",
    "    '111': 'MeD',\n",
    "    '2': 'MePV',\n",
    "    '13':'CeA',\n",
    "    '112': 'BMA',\n",
    "    '14': 'AA',\n",
    "    '16': 'EA',\n",
    "    '12': 'STIA',\n",
    "    '15': 'VP'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def reformat_columns(df):\n",
    "    # combine column names and remove levels\n",
    "    df_new = pd.DataFrame()\n",
    "    areas = df.columns.get_level_values('area').unique()\n",
    "    freqs = df.columns.get_level_values('freq').unique()\n",
    "    stages = df.columns.get_level_values('stage').unique()\n",
    "\n",
    "    df_new.index = df.index\n",
    "    for area in areas:\n",
    "        for freq in freqs:\n",
    "            for stage in stages:\n",
    "\n",
    "                col_name = (area, freq, stage)\n",
    "                \n",
    "                area_name = area_num_to_name_map[area]\n",
    "                if \"diffduring\" in stage.lower():\n",
    "                    new_stage = 'enc_pre'\n",
    "                elif\"diffafter\" in stage.lower():\n",
    "                    new_stage = 'post_pre'\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                new_freq = freq.replace('-','_') + 'Hz'\n",
    "                \n",
    "                \n",
    "                new_col_name = '_'.join((area_name, new_freq, new_stage))\n",
    "\n",
    "                df_new[new_col_name] = df[col_name]\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff2369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aff_lfp = reformat_columns(df_aff_lfp_raw)\n",
    "\n",
    "df_avv_lfp = reformat_columns(df_avv_lfp_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f02ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add variables befor concatination\n",
    "df_aff_enc_pre = pd.read_excel(path_to_affiliative_enc_pre,None)\n",
    "# df_aff_enc_pre['sociability'] = 'affiliative'\n",
    "# df_aff_enc_pre['stage'] = 'enc_pre'\n",
    "\n",
    "df_aff_post_pre = pd.read_excel(path_to_affiliative_post_pre,None)\n",
    "# df_aff_post_pre['sociability'] = 'affiliative'\n",
    "# df_aff_post_pre['stage'] = 'post_pre'\n",
    "\n",
    "\n",
    "df_avv_enc_pre = pd.read_excel(path_to_aversive_enc_pre,None)\n",
    "# df_avv_enc_pre['sociability'] = 'aversive'\n",
    "# df_avv_enc_pre['stage'] = 'enc_pre'\n",
    "\n",
    "\n",
    "df_avv_post_pre = pd.read_excel(path_to_aversive_post_pre,None)\n",
    "# df_avv_post_pre['sociability'] = 'aversive'\n",
    "# df_avv_post_pre['stage'] = 'post_pre'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6936c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_keywords = {'First': '4_18Hz', 'Second':'30_80Hz'}\n",
    "stage_keywords = {'During':'enc_pre', 'After':'post_pre'}\n",
    "substrings_to_remove = ['During', 'After','Before', 'First', 'Second']\n",
    "ignore_keyworks = ['Norm', 'files']\n",
    "\n",
    "def remove_columns_with_fewer_values(df, N=5):\n",
    "    # Get the count of non-null values in each column\n",
    "    column_counts = df.count()\n",
    "\n",
    "    # Filter columns based on count condition\n",
    "    columns_to_remove = column_counts[column_counts < N].index\n",
    "\n",
    "    # Drop the columns from the DataFrame\n",
    "    updated_df = df.drop(columns=columns_to_remove)\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "def reformat_dict_to_table(df_dict, file_df):\n",
    "# def reformat_dict_to_table(df_dict, freq_keywords, stage_keywords, ignore_keyworks, substrings_to_remove):\n",
    "    ret_df_list = []\n",
    "    for sheet, df in df_dict.items():\n",
    "        df = df.copy()\n",
    "        # ignore first and last sheets that contain a summary and list of file names\n",
    "        if any(substring in sheet for substring in ignore_keyworks): \n",
    "            continue\n",
    "            \n",
    "        if isinstance(df, str):\n",
    "            print(df)\n",
    "            continue\n",
    "            \n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "        \n",
    "         # Remove all substrings to keep just the area name\n",
    "        area_name = sheet\n",
    "        for sub_string_to_remove in substrings_to_remove:\n",
    "            area_name = area_name.replace(sub_string_to_remove,'')\n",
    "        \n",
    "        for fk, freq in  freq_keywords.items():\n",
    "            if fk in sheet:\n",
    "                this_freq = freq_keywords[fk]\n",
    "            for sk in stage_keywords.keys():\n",
    "                if sk in sheet:\n",
    "                    this_stage = stage_keywords[sk]\n",
    "        \n",
    "                # Rename all column names to match\n",
    "        \n",
    "        for col in df.columns:\n",
    "            area_pair = [col, area_name]\n",
    "            area_pair.sort()\n",
    "            \n",
    "            df.rename(columns={col:f'{area_pair[0]}_{area_pair[1]}_{this_freq}_{this_stage}'}, inplace=True)\n",
    "        \n",
    "        \n",
    "        df.dropna(axis=1, how='all', inplace=True)\n",
    "        df = remove_columns_with_fewer_values(df)\n",
    "        ret_df_list.append(df)\n",
    "        \n",
    "    df_ret = pd.concat(ret_df_list,axis=1)\n",
    "    df_ret['files'] = file_df.values\n",
    "    return df_ret\n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25ef5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aff_enc_pre_rectified = reformat_dict_to_table(df_aff_enc_pre, df_files_aff)\n",
    "df_aff_enc_post_rectified = reformat_dict_to_table(df_aff_post_pre, df_files_aff)\n",
    "df_aff = pd.concat([df_aff_enc_pre_rectified.drop('files', axis=1), df_aff_enc_post_rectified], axis=1)\n",
    "df_aff = pd.concat([df_aff, df_aff_lfp.reset_index(drop=True)], axis=1)\n",
    "df_aff['sociability'] = 'affiliative'\n",
    "\n",
    "\n",
    "\n",
    "df_avv_enc_pre_rectified = reformat_dict_to_table(df_avv_enc_pre, df_files_avv)\n",
    "df_avv_enc_post_rectified = reformat_dict_to_table(df_avv_post_pre, df_files_avv)\n",
    "df_avv = pd.concat([df_avv_enc_pre_rectified.drop('files', axis=1), df_avv_enc_post_rectified], axis=1)\n",
    "df_avv = pd.concat([df_avv, df_avv_lfp.reset_index(drop=True)], axis=1)\n",
    "df_avv['sociability'] = 'aversive'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfb8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d54a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avv_cols = df_avv.columns\n",
    "df_aff_cols = df_aff.columns\n",
    "common_cols = set(df_aff_cols).intersection(set(df_avv_cols))\n",
    "df_aff = df_aff[common_cols]\n",
    "df_avv = df_avv[common_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0563f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([df_aff, df_avv])\n",
    "all_df['rat_number'] = all_df['files'].apply(extract_ratnum_from_file_name)\n",
    "all_df['day_number'] = all_df['files'].apply(extract_daynum_from_file_name)\n",
    "all_df = all_df.set_index('files')\n",
    "# all_df.to_excel(osp.join(folder_path, 'combined_data.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c68f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91b84959",
   "metadata": {},
   "source": [
    "## Preliminary feature selection via statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aedcd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, StratifiedGroupKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "############################\n",
    "import sklearn.neighbors._base\n",
    "import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.special import logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d40fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract values\n",
    "\n",
    "df_values = all_df.drop('sociability',axis=1).values\n",
    "y = all_df['sociability'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53ec006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18344cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_var(func_handle, X_train,X_test, method='reuse', func_parameters=None):\n",
    "    if func_parameters is None:\n",
    "        func_train = func_handle()\n",
    "    else:\n",
    "        func_train = func_handle(**func_parameters)\n",
    "            \n",
    "    X_train_trans = func_train.fit_transform(X_train)\n",
    "    \n",
    "    if method == 'reuse':\n",
    "        X_test_trans = func_train.transform(X_test)\n",
    "        func_test = func_train\n",
    "    # create new instance and refit on test data\n",
    "    elif method == 'new':\n",
    "        if func_parameters is None:\n",
    "            func_test = func_handle()\n",
    "        else:\n",
    "            func_test = func_handle(**func_parameters)\n",
    "        X_test_trans = func_test.fit_transform(X_test)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input value. The value must be either 'reuse' or 'new'.\")\n",
    "    return X_train_trans, X_test_trans, func_train, func_test\n",
    "\n",
    "def eval_model(y_test, y_test_pred):\n",
    "#     print(f'y:{y_test}')\n",
    "#     print(f'y_pred:{y_test_pred}')\n",
    "    # Calculating evaluation metrics on the testing set\n",
    "    ret_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    ret_precision = precision_score(y_test, y_test_pred, pos_label=\"affiliative\")\n",
    "    ret_recall = recall_score(y_test, y_test_pred,pos_label=\"affiliative\")\n",
    "    ret_f1 = f1_score(y_test, y_test_pred,pos_label=\"affiliative\")\n",
    "#     ret_roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "    ret = {\n",
    "        'accuracy':np.round(ret_accuracy, 3),\n",
    "        'precision':np.round(ret_precision, 3),\n",
    "        'recall':np.round(ret_recall, 3),\n",
    "        'f1':np.round(ret_f1, 3),\n",
    "    }\n",
    "    \n",
    "\n",
    "    return ret\n",
    "\n",
    "def sum_model_results(y, y_pred, \n",
    "                      confidence_levels, affiliative,\n",
    "                      dataset):\n",
    "    df_results = pd.DataFrame()\n",
    "    df_results['GT'] = y\n",
    "    df_results['predicted'] = y_pred\n",
    "    df_results['correct'] = df_results['GT'] == df_results['predicted']\n",
    "    df_results['confidence'] = confidence_levels\n",
    "    df_results['affiliative_level'] = affiliative\n",
    "\n",
    "    return df_results\n",
    "\n",
    "def sum_all_results(y_train, y_train_pred, y_test, y_test_pred, **kwargs):\n",
    "    \n",
    "    ret_train = eval_model(y_train,y_train_pred)\n",
    "    ret_test = eval_model(y_test,y_test_pred)\n",
    "    df_res_all = pd.DataFrame.from_dict([ret_test, ret_train])\n",
    "    df_res_all.index = ['test','train']\n",
    "    for param, vals in kwargs.items():\n",
    "        df_res_all[param] = vals\n",
    "    return df_res_all\n",
    "\n",
    "\n",
    "def train_eval_model(config_dict,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    method_name, imputer_name, scaler_name, classifier_name, k_fold, ind):\n",
    "    \n",
    "    \n",
    "    scaler = config_dict['scaler'][scaler_name]\n",
    "    imputer_class = config_dict['imputer'][imputer_name]\n",
    "    \n",
    "    if ('imputer_param' in config_dict) and (imputer_name in config_dict['imputer_param']):\n",
    "        imputer_param = config_dict['imputer_param'][imputer_name]\n",
    "    else:\n",
    "        imputer_param = None\n",
    "    \n",
    "    classifier_class = config_dict['model'][classifier_name]\n",
    "\n",
    "    \n",
    "    # impute\n",
    "    X_train_imputed, X_test_imputed, imputer_train, imputer_test = transform_var(\n",
    "        imputer_class, X_train, X_test, method_name, imputer_param)\n",
    "\n",
    "    # scale\n",
    "    X_train_scaled, X_test_scaled, scaler_train, scaler_test= transform_var(\n",
    "        imputer_class, X_train_imputed, X_test_imputed, method_name)\n",
    "\n",
    "    # train classifier\n",
    "    if ('model_param' in config_dict) and (classifier_name in config_dict['model_param']):\n",
    "        model = classifier_class(**config_dict['model_param'][classifier_name])\n",
    "    else: \n",
    "        model = classifier_class()\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # predict\n",
    "\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    y_test_pred_prob = model.predict_proba(X_test_scaled)\n",
    "    y_train_pred_prob = model.predict_proba(X_train_scaled)\n",
    "\n",
    "    test_confidence_levels = y_test_pred_prob.max(axis=1)\n",
    "    train_confidence_levels = y_train_pred_prob.max(axis=1)\n",
    "\n",
    "    test_affiliative = y_test_pred_prob[:,0]\n",
    "    train_affiliative = y_train_pred_prob[:,0]\n",
    "\n",
    "    sum_results = sum_all_results(\n",
    "        y_train, y_train_pred, y_test, y_test_pred,\n",
    "        method = method_name,\n",
    "        imputer= imputer_name,\n",
    "        scaler = scaler_name, \n",
    "        model = classifier_name,\n",
    "        kfold = k_fold,\n",
    "        ind = ind\n",
    "    )\n",
    "\n",
    "    df_results_train = sum_model_results(y_train, y_train_pred,train_confidence_levels, train_affiliative, dataset='train')\n",
    "    df_results_train['dataset'] = 'train'\n",
    "    df_results_test = sum_model_results(y_test, y_test_pred,test_confidence_levels, test_affiliative ,dataset='test')\n",
    "    df_results_test['dataset'] = 'test'\n",
    "    df_results_all = pd.concat([df_results_test,df_results_train])\n",
    "    df_results_all\n",
    "    \n",
    "    df_results_all['method'] = method_name\n",
    "    df_results_all['imputer'] = imputer_name\n",
    "    df_results_all['scaler'] = scaler_name\n",
    "    df_results_all['model'] = classifier_name\n",
    "    df_results_all['kfold'] = k_fold\n",
    "    df_results_all['ind'] = ind\n",
    "\n",
    "    return sum_results, df_results_all\n",
    "\n",
    "def model_selection(config_dict, X, y, subject_id):\n",
    "    all_results_summary = []\n",
    "    all_raw_results = []\n",
    "    errors_log = []\n",
    "    for k_fold in config_dict['k_fold']:\n",
    "        stratified_group_kfold = StratifiedGroupKFold(n_splits=k_fold)\n",
    "        \n",
    "        for ind, (train_index, test_index) in enumerate(stratified_group_kfold.split(X, y, groups=subject_id)):\n",
    "        \n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            # mamke sure that there is nan columns:\n",
    "            X_train_nan_flag = np.any(np.all(np.isnan(X_train), axis=0))\n",
    "            X_test_nan_flag = np.any(np.all(np.isnan(X_test), axis=0))\n",
    "            if X_train_nan_flag or X_test_nan_flag:\n",
    "                print(f'Detected nan columns')\n",
    "                continue\n",
    "            \n",
    "            for method_name in config_dict['method']:\n",
    "                for imputer_name in config_dict['imputer'].keys():\n",
    "                    for scaler_name in config_dict['scaler'].keys():\n",
    "                        for classifier_name in config_dict['model'].keys():\n",
    "#                             sum_results, raw_results = train_eval_model(\n",
    "#                                     config_dict,\n",
    "#                                     X_train, y_train, X_test, y_test,\n",
    "#                                     method_name,\n",
    "#                                     imputer_name,\n",
    "#                                     scaler_name,\n",
    "#                                     classifier_name,\n",
    "#                                     k_fold, ind)\n",
    "#                             all_results_summary.append(sum_results)\n",
    "#                             all_raw_results.append(raw_results)\n",
    "                            try:\n",
    "                                print(f'Evaluating new parameters:')\n",
    "                               \n",
    "                                \n",
    "        \n",
    "                                sum_results, raw_results = train_eval_model(\n",
    "                                    config_dict,\n",
    "                                    X_train, y_train, X_test, y_test,\n",
    "                                    method_name,\n",
    "                                    imputer_name,\n",
    "                                    scaler_name,\n",
    "                                    classifier_name,\n",
    "                                    k_fold, ind)\n",
    "                                all_results_summary.append(sum_results)\n",
    "                                all_raw_results.append(raw_results)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error: {e}\")\n",
    "                                error_df = dict()\n",
    "                                error_df['method'] = method_name\n",
    "                                error_df['imputer'] = imputer_name\n",
    "                                error_df['scaler'] = scaler_name\n",
    "                                error_df['model'] = classifier_name\n",
    "                                error_df['error'] = e\n",
    "                                errors_log.append(error_df)\n",
    "                                continue\n",
    "                                \n",
    "    return all_results_summary, all_raw_results, errors_log\n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e2b81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imputer_class = MissForest\n",
    "# classifier_class = RandomForestClassifier\n",
    "# method = 'reuse'\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_values, y, test_size=0.33)\n",
    "# # impute\n",
    "# X_train_imputed, X_test_imputed, imputer_train, imputer_test = transform_var(imputer_class, X_train, X_test, method)\n",
    "\n",
    "# # scale\n",
    "# X_train_scaled, X_test_scaled, scaler_train, scaler_test= transform_var(imputer_class, X_train_imputed, X_test_imputed, method)\n",
    "\n",
    "# # train classifier\n",
    "# model = classifier_class()\n",
    "# model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # predict\n",
    "# y_train_pred = model.predict(X_train_scaled)\n",
    "# y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# y_test_pred_prob = model.predict_proba(X_test_scaled)\n",
    "# y_train_pred_prob = model.predict_proba(X_train_scaled)\n",
    "\n",
    "# test_confidence_levels = y_test_pred_prob.max(axis=1)\n",
    "# train_confidence_levels = y_train_pred_prob.max(axis=1)\n",
    "\n",
    "# test_affiliative = y_test_pred_prob[:,0]\n",
    "# train_affiliative = y_train_pred_prob[:,0]\n",
    "\n",
    "# sum_results = sum_all_results(y_train, y_train_pred, y_test, y_test_pred)\n",
    "\n",
    "# df_results_train = sum_model_results(y_train, y_train_pred,train_confidence_levels, train_affiliative, dataset='train')\n",
    "# df_results_train['dataset'] = 'train'\n",
    "# df_results_test = sum_model_results(y_test, y_test_pred,test_confidence_levels, test_affiliative ,dataset='test')\n",
    "# df_results_test['dataset'] = 'test'\n",
    "# df_results_all = pd.concat([df_results_test,df_results_train])\n",
    "# df_results_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c90d6e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# decomposer = PCA(n_components=2)\n",
    "# # decomposer = TSNE(n_components=2, perplexity=10)\n",
    "\n",
    "\n",
    "# X_train_decomp = decomposer.fit_transform(X_train_standard)\n",
    "\n",
    "\n",
    "# # decomposer = PCA(n_components=2)\n",
    "# # X_test_decomp = decomposer.fit_transform(X_test_standard)\n",
    "# X_test_decomp = decomposer.transform(X_test_standard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b4c6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_train = pd.DataFrame()\n",
    "# res_train[['comp1','comp2']] = X_train_decomp\n",
    "# res_train['dataset'] = 'train'\n",
    "# res_train['GT'] = y_train\n",
    "\n",
    "# res_test = pd.DataFrame()\n",
    "# res_test[['comp1','comp2']] = X_test_decomp\n",
    "# res_test['dataset'] = 'test'\n",
    "# res_test['GT'] = y_test\n",
    "# res_all = pd.concat([res_train,res_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e748820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.catplot(data=res_all, x='comp1', y='comp2', col='dataset', hue='GT')\n",
    "# g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad295ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Variable  Statistic   p-value\n",
      "44        EA_30_80Hz_enc_pre       12.0  0.011655\n",
      "3         AA_30_80Hz_enc_pre       41.0  0.017954\n",
      "49  CeA_MeD_30_80Hz_post_pre       61.0  0.018207\n",
      "6      AA_MeD_4_18Hz_enc_pre      110.0  0.020729\n",
      "4          AA_4_12Hz_enc_pre       43.0  0.023270\n",
      "..                       ...        ...       ...\n",
      "11    EA_MeD_30_80Hz_enc_pre       43.0  0.967849\n",
      "41     EA_MeD_4_18Hz_enc_pre       43.0  0.967849\n",
      "30      CeA_30_80Hz_post_pre       49.0  0.969929\n",
      "20       MePV_4_12Hz_enc_pre       50.0  0.971018\n",
      "40   MeD_STIA_4_18Hz_enc_pre       28.0  1.000000\n",
      "\n",
      "[62 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "MIN_N_SESSIONS = 5\n",
    "\n",
    "def variable_significance_table(df):\n",
    "    significance_table = pd.DataFrame(columns=[\"Variable\", \"Statistic\", \"p-value\"])\n",
    "\n",
    "    predictor = df[\"sociability\"]\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column != \"sociability\":\n",
    "            \n",
    "            variable = df[column].values\n",
    "            \n",
    "            variable_aff = variable[np.where(predictor=='affiliative')]\n",
    "            variable_avv = variable[np.where(predictor=='aversive')]\n",
    "            \n",
    "            \n",
    "            variable_aff = variable_aff[~pd.isnull(variable_aff)]\n",
    "            variable_avv = variable_avv[~pd.isnull(variable_avv)]\n",
    "            \n",
    "            if len(variable_aff)<MIN_N_SESSIONS or len(variable_avv)< MIN_N_SESSIONS:\n",
    "                continue\n",
    "\n",
    "            statistic, p_value = mannwhitneyu(variable_avv, variable_aff)\n",
    "\n",
    "            significance_table = significance_table.append(\n",
    "                {\"Variable\": column, \"Statistic\": statistic, \"p-value\": p_value},\n",
    "                ignore_index=True\n",
    "            )\n",
    "\n",
    "    return significance_table\n",
    "\n",
    "\n",
    "sig_table_all = variable_significance_table(df=all_df)\n",
    "sig_table_all = sig_table_all.sort_values('p-value')\n",
    "sig_table_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6163c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2fa0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e35ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig_cut_off = 0.1\n",
    "# sig_table = sig_table_all\n",
    "# sig_table_filt = sig_table.loc[sig_table['p-value']<sig_cut_off]\n",
    "# n_var_start = 3\n",
    "# n_params = len(sig_table_filt)\n",
    "# all_vars = list(sig_table_filt.Variable.values)\n",
    "\n",
    "# current_vars = all_vars[:n_var_start]\n",
    "# vars_to_test = all_vars[n_var_start:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77557946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_vars + [vars_to_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87c81f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parameters(config_dict, sig_table, all_df):\n",
    "    def run_per_param(var_names, all_df):\n",
    "        \n",
    "        X = all_df[var_names].values\n",
    "\n",
    "        samples_to_remove = ~np.all(np.isnan(X),axis=1)\n",
    "        y = all_df.iloc[samples_to_remove]['sociability'].values\n",
    "        subject_id = all_df.iloc[samples_to_remove]['rat_number'].values\n",
    "        X = all_df.iloc[samples_to_remove][var_names].values\n",
    "\n",
    "\n",
    "        ret, raw_results, errors_log = model_selection(config_dict=config_dict, X=X, y=y, subject_id=subject_id)\n",
    "        \n",
    "        \n",
    "        raw_results_df = pd.concat(raw_results)\n",
    "\n",
    "        ret_df = pd.concat(ret)\n",
    "        ret_df = ret_df.reset_index().rename(columns={'index':'dataset'})\n",
    "        mean_df = ret_df.drop('ind',axis=1).groupby(['dataset','method', 'imputer', 'scaler', 'model', 'kfold']).mean().reset_index()\n",
    "\n",
    "        # Add a new column 'ind' that counts the number of rows for each group\n",
    "        mean_df['ind'] = ret_df.drop('ind',axis=1).groupby(['dataset','method', 'imputer', 'scaler', 'model', 'kfold']).size().reset_index(name='ind')['ind']\n",
    "\n",
    "        return mean_df, raw_results_df, ret_df, errors_log\n",
    "    all_errors_log = []\n",
    "    best_f1 = 0\n",
    "    best_sum_table = []\n",
    "    best_raw_rable = []\n",
    "    best_ret_df = []\n",
    "    n_var_start = 3\n",
    "    sig_cut_off = 0.1\n",
    "    sig_table_filt = sig_table.loc[sig_table['p-value']<sig_cut_off]\n",
    "    \n",
    "    n_params = len(sig_table_filt)\n",
    "    all_vars = list(sig_table_filt.Variable.values)\n",
    "    \n",
    "    current_vars = all_vars[:n_var_start]\n",
    "    vars_to_test = all_vars[n_var_start:]\n",
    "    \n",
    "    for new_var in vars_to_test:\n",
    "        var_names = current_vars + [new_var]\n",
    "#         print(\"====================== New param ====================\")\n",
    "#         mean_df, raw_results_df, ret_df, errors_log = run_per_param(var_names,all_df)\n",
    "#         this_best_sum_df = mean_df.loc[mean_df['dataset']=='test'].sort_values('f1', ascending=False).iloc[0]\n",
    "#         all_errors_log.append(errors_log)\n",
    "#         this_best_f1 = mean_df.loc[mean_df['dataset']=='test']['f1'].max()\n",
    "#         if this_best_f1 > best_f1:\n",
    "#             current_vars.append(new_var)\n",
    "\n",
    "#             print(f'New best f1 was found: {this_best_f1}')\n",
    "#             print(f'Adding: {new_var}')\n",
    "#             print(f'Current vars: {current_vars}')\n",
    "\n",
    "#             best_f1 = this_best_f1\n",
    "#             best_sum_table = mean_df\n",
    "#             best_ret_df = ret_df\n",
    "#             best_raw_rable = raw_results_df.loc[\n",
    "#                 (raw_results_df['method'] == this_best_sum_df.method)&\n",
    "#                 (raw_results_df['imputer'] == this_best_sum_df.imputer)&\n",
    "#                 (raw_results_df['scaler'] == this_best_sum_df.scaler)&\n",
    "#                 (raw_results_df['model'] == this_best_sum_df.model)&\n",
    "#                 (raw_results_df['kfold'] == this_best_sum_df.kfold)\n",
    "#             ]\n",
    "#         else:\n",
    "#             print(f'Variable {new_var} did not improve the model')\n",
    "        try:\n",
    "            print(\"====================== New param ====================\")\n",
    "            mean_df, raw_results_df, ret_df, errors_log = run_per_param(var_names,all_df)\n",
    "            this_best_sum_df = mean_df.loc[mean_df['dataset']=='test'].sort_values('f1', ascending=False).iloc[0]\n",
    "            all_errors_log.append(errors_log)\n",
    "            this_best_f1 = mean_df.loc[mean_df['dataset']=='test']['f1'].max()\n",
    "            if this_best_f1 > best_f1:\n",
    "                current_vars.append(new_var)\n",
    "            \n",
    "                print(f'*********New best f1 was found: {this_best_f1}************')\n",
    "                print(f'Adding: {new_var}')\n",
    "                print(f'Current vars: {current_vars}')\n",
    "                print(f'method:{this_best_sum_df.method}')\n",
    "                print(f'imputer:{this_best_sum_df.imputer}')\n",
    "                print(f'model:{this_best_sum_df.model}')\n",
    "\n",
    "                best_f1 = this_best_f1\n",
    "                best_sum_table = mean_df\n",
    "                best_ret_df = ret_df\n",
    "                best_raw_rable = raw_results_df.loc[\n",
    "                    (raw_results_df['method'] == this_best_sum_df.method)&\n",
    "                    (raw_results_df['imputer'] == this_best_sum_df.imputer)&\n",
    "                    (raw_results_df['scaler'] == this_best_sum_df.scaler)&\n",
    "                    (raw_results_df['model'] == this_best_sum_df.model)&\n",
    "                    (raw_results_df['kfold'] == this_best_sum_df.kfold)\n",
    "                ]\n",
    "            else:\n",
    "                print(f'Variable {new_var} did not improve the model')\n",
    "        except Exception as e:\n",
    "            print('=================Error - start ==================')\n",
    "            print(e)\n",
    "            print('=================Error - end ==================')\n",
    "            continue\n",
    "            \n",
    "    return best_f1, best_sum_table,best_raw_rable, current_vars,ret_df, all_errors_log\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abb1c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start with top 3 variables\n",
    "# top_3_vars = sig_table_all.Variable[:3].values\n",
    "# X = all_df[top_3_vars].values\n",
    "\n",
    "# samples_to_remove = ~np.all(np.isnan(X),axis=1)\n",
    "# y = all_df.iloc[samples_to_remove]['sociability'].values\n",
    "# subject_id = all_df.iloc[samples_to_remove]['rat_number'].values\n",
    "# X = all_df.iloc[samples_to_remove][top_3_vars].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949957a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15de5159",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict_test = {\n",
    "    'method': ['new'],\n",
    "    'k_fold': [3,4,5],\n",
    "    'imputer': {\n",
    "        'iterative_imputer': IterativeImputer,\n",
    "    },\n",
    "    'imputer_param': {\n",
    "        'iterative_imputer': {'max_iter':1000},\n",
    "    },\n",
    "    'scaler':{\n",
    "        'standard_scaler': StandardScaler,\n",
    "    },\n",
    "   'model':{\n",
    "    'random_forest':RandomForestClassifier,\n",
    "    'logistic_regression': LogisticRegression,\n",
    "    'svm': svm.SVC,\n",
    "    'naive_basian': GaussianNB,\n",
    "    'knn_classifier': KNeighborsClassifier,\n",
    "   },\n",
    "    'model_param':{\n",
    "    'svm':{'probability': True},\n",
    "    'knn_classifier':{'n_neighbors': 5}\n",
    "    }\n",
    "}\n",
    "\n",
    "config_dict = {\n",
    "    'method': ['reuse'],\n",
    "#     'method': ['reuse', 'new'],\n",
    "    'k_fold': [3,4,5],\n",
    "    'imputer': {\n",
    "        'missforest':MissForest,\n",
    "        'iterative_imputer': IterativeImputer,\n",
    "        'knn_imputer': KNNImputer        \n",
    "    },\n",
    "    'imputer_param': {\n",
    "        'iterative_imputer': {'max_iter':1000},\n",
    "    },\n",
    "    'scaler':{\n",
    "        'standard_scaler': StandardScaler,\n",
    "#         'no_scaler': lambda x: x,\n",
    "    },\n",
    "    'model':{\n",
    "        'random_forest':RandomForestClassifier,\n",
    "        'logistic_regression': LogisticRegression,\n",
    "        'svm': svm.SVC,\n",
    "        'naive_basian': GaussianNB,\n",
    "        'knn_classifier': KNeighborsClassifier,\n",
    "    },\n",
    "    'model_param':{\n",
    "        'svm':{'probability': True},\n",
    "        'knn_classifier':{'n_neighbors': 5}\n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e02704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== New param ====================\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Detected nan columns\n",
      "Detected nan columns\n",
      "New best f1 was found: 0.7823333333333333\n",
      "Adding: AA_MeD_4_18Hz_enc_pre\n",
      "Current vars: ['EA_30_80Hz_enc_pre', 'AA_30_80Hz_enc_pre', 'CeA_MeD_30_80Hz_post_pre', 'AA_MeD_4_18Hz_enc_pre']\n",
      "====================== New param ====================\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Detected nan columns\n",
      "Detected nan columns\n",
      "Variable AA_4_12Hz_enc_pre did not improve the model\n",
      "====================== New param ====================\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Detected nan columns\n",
      "Detected nan columns\n",
      "New best f1 was found: 0.8233333333333334\n",
      "Adding: CeA_MeD_4_18Hz_enc_pre\n",
      "Current vars: ['EA_30_80Hz_enc_pre', 'AA_30_80Hz_enc_pre', 'CeA_MeD_30_80Hz_post_pre', 'AA_MeD_4_18Hz_enc_pre', 'CeA_MeD_4_18Hz_enc_pre']\n",
      "====================== New param ====================\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Detected nan columns\n",
      "Detected nan columns\n",
      "Variable AA_MeD_30_80Hz_enc_pre did not improve the model\n",
      "====================== New param ====================\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings(record=True):\n",
    "    best_f1, best_sum_table,best_raw_rable, current_vars, all_errors_log = select_parameters(config_dict = config_dict, sig_table = sig_table_all, all_df = all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc956355",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f5f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c83f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_sum_table.loc[best_sum_table['dataset']=='test'].sort_values('f1', ascending=False).iloc[0])\n",
    "print(current_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f332c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_raw_rable.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb24192",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results_df = pd.concat(raw_results)\n",
    "\n",
    "ret_df = pd.concat(ret)\n",
    "ret_df = ret_df.reset_index().rename(columns={'index':'dataset'})\n",
    "mean_df = ret_df.drop('ind',axis=1).groupby(['dataset','method', 'imputer', 'scaler', 'model', 'kfold']).mean().reset_index()\n",
    "\n",
    "# Add a new column 'ind' that counts the number of rows for each group\n",
    "mean_df['ind'] = ret_df.drop('ind',axis=1).groupby(['dataset','method', 'imputer', 'scaler', 'model', 'kfold']).size().reset_index(name='ind')['ind']\n",
    "mean_df\n",
    "# ret_df.drop('ind',axis=1).groupby(['method', 'imputer', 'scaler','model', 'kfold']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7a5c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df = mean_df.loc[mean_df['dataset']=='test'].sort_values('f1', ascending=False).iloc[0]\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results_df.loc[\n",
    "    (raw_results_df['method'] == best_df.method)&\n",
    "    (raw_results_df['imputer'] == best_df.imputer)&\n",
    "    (raw_results_df['scaler'] == best_df.scaler)&\n",
    "    (raw_results_df['model'] == best_df.model)&\n",
    "    (raw_results_df['kfold'] == best_df.kfold)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c68274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significan columns:\n",
    "sig_table = sig_table_all.loc[sig_table_all['p-value']<=0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8de005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b49fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_df = all_df[sig_table['Variable']].copy()\n",
    "all_data_flag = np.sum(np.invert(np.isnan(sig_df.values)), axis=1)\n",
    "sig_df['sociability'] = all_df['sociability']\n",
    "ind_train = np.logical_and(all_data_flag>0, all_data_flag<4)\n",
    "ind_test = all_data_flag==4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = sig_df.loc[ind_train].copy()\n",
    "df_train['dataset'] = 'train'\n",
    "df_test = sig_df.loc[ind_test].copy()\n",
    "df_test['dataset'] = 'test'\n",
    "\n",
    "df_dataset = pd.concat([df_train,df_test])\n",
    "# df_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the destribution of classes\n",
    "result = df_dataset.groupby(['dataset', 'sociability']).size().unstack('sociability')\n",
    "print(result)\n",
    "\n",
    "# transfere sessions of rat 19 from train to test\n",
    "# transfere sessions of rat 23 from test to train\n",
    "# transfere sessions of rat 4 from test to train\n",
    "# df_dataset.loc[df_dataset.index.str.contains('Rat23'),'dataset'] = 'train'\n",
    "# df_dataset.loc[df_dataset.index.str.contains('Rat4'),'dataset'] = 'train'\n",
    "# df_dataset.loc[df_dataset.index.str.contains('Rat19'),'dataset'] = 'test'\n",
    "\n",
    "result = df_dataset.groupby(['dataset', 'sociability']).size().unstack('sociability')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2980a2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa0b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032638dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_dataset.loc[df_dataset['dataset'] == 'train' ].drop(['sociability','dataset'], axis=1).values\n",
    "y_train = df_dataset.loc[df_dataset['dataset'] == 'train' ]['sociability']\n",
    "\n",
    "X_test = df_dataset.loc[df_dataset['dataset'] == 'test' ].drop(['sociability','dataset'], axis=1).values\n",
    "y_test = df_dataset.loc[df_dataset['dataset'] == 'test' ]['sociability']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af65ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b1844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = tree.DecisionTreeClassifier()\n",
    "# model = LogisticRegression()\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# X_train = data.iloc[train_inds].drop('0', axis=1).values\n",
    "# y_train = data.iloc[train_inds]['0'].values\n",
    "\n",
    "# imputer = MissForest()\n",
    "imputer = IterativeImputer(max_iter=5000)\n",
    "# imputer = KNNImputer()\n",
    "\n",
    "\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "scaler = StandardScaler()\n",
    "X_train_imp = scaler.fit_transform(X_train_imp, y=y_train)\n",
    "\n",
    "\n",
    "# X_test = data.iloc[test_inds].drop('0', axis=1).values\n",
    "# y_test = data.loc[test_inds]['0'].values\n",
    "X_test_imp = imputer.fit_transform(X_test)\n",
    "X_test_imp = scaler.transform(X_test_imp)\n",
    "\n",
    "model.fit(X_train_imp, y_train)\n",
    "y_train_pred = model.predict(X_train_imp)\n",
    "y_test_pred = model.predict(X_test_imp)\n",
    "\n",
    "y_test_pred_prob = model.predict_proba(X_test_imp)\n",
    "y_train_pred_prob = model.predict_proba(X_train_imp)\n",
    "\n",
    "test_confidence_levels = y_test_pred_prob.max(axis=1)\n",
    "train_confidence_levels = y_train_pred_prob.max(axis=1)\n",
    "\n",
    "test_affiliative = y_test_pred_prob[:,0]\n",
    "train_affiliative = y_train_pred_prob[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a2142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_model_results(y, y_pred, \n",
    "                      confidence_levels, affiliative,\n",
    "                      dataset):\n",
    "    df_results = pd.DataFrame(df_dataset.loc[df_dataset['dataset']==dataset].index)\n",
    "    df_results['GT'] = y\n",
    "    df_results['predicted'] = y_pred\n",
    "    df_results['correct'] = df_results['GT'] == df_results['predicted']\n",
    "    df_results['confidence'] = confidence_levels\n",
    "    df_results['affiliative_level'] = affiliative\n",
    "\n",
    "    return df_results\n",
    "\n",
    "def sum_all_results(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    \n",
    "    ret_train = eval_model(y_train.values,y_train_pred)\n",
    "    ret_test = eval_model(y_test.values,y_test_pred)\n",
    "    df_res_all = pd.DataFrame.from_dict([ret_test, ret_train])\n",
    "    df_res_all.index = ['test','train']\n",
    "    return df_res_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_all_results(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31310c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_affiliative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_results = sum_all_results(y_train, y_train_pred, y_test, y_test_pred)\n",
    "df_results_train = sum_model_results(y_train.values, y_train_pred,train_confidence_levels, train_affiliative, dataset='train')\n",
    "df_results_train['dataset'] = 'train'\n",
    "df_results_test = sum_model_results(y_test.values, y_test_pred,test_confidence_levels, test_affiliative ,dataset='test')\n",
    "df_results_test['dataset'] = 'test'\n",
    "df_results_all = pd.concat([df_results_test,df_results_train])\n",
    "df_results_all\n",
    "\n",
    "\n",
    "# df_results_test.to_clipboard()\n",
    "\n",
    "# print(df_results_test)\n",
    "# print(df_results_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_test = eval_model(y_test.values,y_test_pred)\n",
    "ret_train = eval_model(y_train.values,y_train_pred)\n",
    "df_res_all = pd.DataFrame.from_dict([ret_test, ret_train])\n",
    "df_res_all.index = ['test','train']\n",
    "df_res_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d83663",
   "metadata": {},
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb7094",
   "metadata": {},
   "source": [
    "Feature selection steps:\n",
    "\n",
    "1. Find top 2 candidates\n",
    "2. Train model and get results\n",
    "3. Add next candiate and repeat step 2.\n",
    "4. If the resutls improved, add this featrue, if not, advance to the next candidate\n",
    "\n",
    "Model trainig steps:\n",
    "\n",
    "1. Split data\n",
    "\n",
    "3. Impute missing values\n",
    "    a. MissForest\n",
    "    b. IterativeImputer\n",
    "    \n",
    "4. rescale data (or not)\n",
    "\n",
    "5. Train model/s\n",
    "    a. svm\n",
    "    b. logistic regression\n",
    "    c. random forest classifier\n",
    "    d. knn classifier\n",
    "    \n",
    "6. Evaluate model/s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112191f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_class = MissForest\n",
    "classifier_class = RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([('imputer', imputer_class()), ('scaler', StandardScaler()),('classifier', classifier_class())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946e1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99014a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ee48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test['dataset'] = 'test'\n",
    "df_results_train['dataset'] = 'train'\n",
    "df_results_all = pd.concat([df_results_train,df_results_test])\n",
    "df_results_all['rat_num'] = df_results_all['files'].apply(extract_ratnum_from_file_name)\n",
    "df_results_all['day_num'] = df_results_all['files'].apply(extract_day_from_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f406ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=df_results_all, x='day_num', y='affiliative_level', hue='GT', col='dataset')\n",
    "sns.lmplot(data=df_results_all, x='day_num', y='affiliative_level', hue='predicted', col='dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e57721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bdc3f2a",
   "metadata": {},
   "source": [
    "## Dimensionality reduction using t-SNE and visualization|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccccb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create the figure and axes\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# # add the plots for each dataframe\n",
    "# df_rats = df_results_all.groupby('rat_num')\n",
    "# for ratnum , df_r in df_rats:\n",
    "#     sns.regplot(x='day_num', y='affiliative_level', data=df_r, fit_reg=True, ci=None, ax=ax, label=ratnum)\n",
    "# ax.set(ylabel='affiliative_level', xlabel='rat_num')\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67650f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df_train.drop(['sociability','dataset'], axis = 1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e1c54d",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f9caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairplot(title, X,y,y_pred):\n",
    "    df_X = pd.DataFrame(X)\n",
    "\n",
    "\n",
    "    df_X = df_X.rename(columns={num:cname for num, cname in enumerate(col_names)})\n",
    "    df_X['GT'] = y\n",
    "    df_X['predicted'] = y_pred\n",
    "    df_X['correct'] = df_X['predicted'] == df_X['GT']\n",
    "\n",
    "    g = sns.pairplot(data=df_X.drop(['predicted','correct'], axis=1), hue='GT')\n",
    "    g.fig.suptitle(f\"{title} Data GT sociability\", y=1.05)\n",
    "\n",
    "    g = sns.pairplot(data=df_X.drop(['GT','correct'], axis=1), hue='predicted')\n",
    "    g.fig.suptitle(f\"{title} Data GT predicted\", y=1.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1123aba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X = X_test\n",
    "y = y_test.values\n",
    "y_pred = y_test_pred\n",
    "title = 'Test - Unimputed'\n",
    "plot_pairplot(title, X,y,y_pred)\n",
    "\n",
    "\n",
    "X = X_train\n",
    "y = y_train.values\n",
    "y_pred = y_train_pred\n",
    "title = 'Train - Unimputed'\n",
    "plot_pairplot(title, X,y,y_pred)\n",
    "\n",
    "X = X_test_imp\n",
    "y = y_test.values\n",
    "y_pred = y_test_pred\n",
    "title = 'Test - Imputed'\n",
    "plot_pairplot(title, X,y,y_pred)\n",
    "\n",
    "X = X_train_imp\n",
    "y = y_train.values\n",
    "y_pred = y_train_pred\n",
    "title = 'Train - Imputed'\n",
    "plot_pairplot(title, X,y,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebada199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e679a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test_imp\n",
    "\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(X)\n",
    "\n",
    "df_results_test[['tsne1','tsne2']] = X_embedded\n",
    "sns.pairplot(df_results_test[['GT','tsne1','tsne2']], hue='GT')\n",
    "sns.pairplot(df_results_test[['predicted','tsne1','tsne2']], hue='predicted')\n",
    "\n",
    "\n",
    "X = X_train_imp\n",
    "\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(X)\n",
    "\n",
    "df_results_train[['tsne1','tsne2']] = X_embedded\n",
    "sns.pairplot(df_results_train[['GT','tsne1','tsne2']], hue='GT')\n",
    "sns.pairplot(df_results_train[['predicted','tsne1','tsne2']], hue='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4768b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = X_test_imp\n",
    "\n",
    "X_embedded = TSNE(n_components=1, learning_rate='auto',\n",
    "                  init='random', perplexity=2).fit_transform(X)\n",
    "\n",
    "# df_results_test[['tsne1','tsne2']] = X_embedded\n",
    "# sns.pairplot(df_results_test[['GT','tsne1','tsne2']], hue='GT')\n",
    "# sns.pairplot(df_results_test[['predicted','tsne1','tsne2']], hue='predicted')\n",
    "\n",
    "df_results_test[['tsne1']] = X_embedded\n",
    "df_results_test['affiliative_level_logit'] = df_results_test['affiliative_level'].apply(logit)\n",
    "sns.lmplot(data=df_results_test, x = 'affiliative_level_logit' ,y = 'tsne1', hue='GT')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eedda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_imp\n",
    "\n",
    "X_embedded = TSNE(n_components=1, learning_rate='auto',\n",
    "                  init='random', perplexity=1).fit_transform(X)\n",
    "\n",
    "# df_results_test[['tsne1','tsne2']] = X_embedded\n",
    "# sns.pairplot(df_results_test[['GT','tsne1','tsne2']], hue='GT')\n",
    "# sns.pairplot(df_results_test[['predicted','tsne1','tsne2']], hue='predicted')\n",
    "\n",
    "df_results_train[['tsne1']] = X_embedded\n",
    "df_results_train['affiliative_level_logit'] = df_results_train['affiliative_level'].apply(logit)\n",
    "sns.(data=df_results_train, x = 'affiliative_level_logit' ,y = 'tsne1', hue='GT')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_imp\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(X)\n",
    "\n",
    "df_results_train[['tsne1','tsne2']] = X_embedded\n",
    "\n",
    "sns.pairplot(df_results_train[['GT','tsne1','tsne2']], hue='GT')\n",
    "\n",
    "sns.pairplot(df_results_train[['predicted','tsne1','tsne2']], hue='predicted')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data (train and test)\n",
    "\n",
    "\n",
    "X = np.append(X_train_imp, X_test_imp, axis=0)\n",
    "y = np.append(y_train, y_test)\n",
    "y_pred = np.append(y_train_pred, y_test_pred)\n",
    "\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=10, n_iter=5000).fit_transform(X)\n",
    "\n",
    "\n",
    "df_res_tsne = pd.DataFrame(y, columns=['GT'])\n",
    "df_res_tsne['dataset'] = np.append(np.full(y_train.shape, \"train\"), np.full(y_test.shape, \"test\"))\n",
    "df_res_tsne['predicted'] = y_pred\n",
    "df_res_tsne['correct'] = df_res_tsne['predicted'] == df_res_tsne['GT']\n",
    "df_res_tsne[['tsne1','tsne2']] = X_embedded\n",
    "#Seaborn pair plot\n",
    "\n",
    "sns.pairplot(df_res_tsne[['GT','tsne1','tsne2']], hue='GT')\n",
    "\n",
    "sns.pairplot(df_res_tsne[['predicted','tsne1','tsne2']], hue='predicted')\n",
    "\n",
    "# # Display the plots\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_tsne.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3faf52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d4ad369",
   "metadata": {},
   "source": [
    "### Impute the missing values of all the dataset before training and testing\n",
    "\n",
    "Performing imputation before splitting the dataset can potentially lead to data leakage and overly optimistic evaluation results. It's generally recommended to split the dataset into training and testing sets before applying any data preprocessing steps, including imputation.\n",
    "\n",
    "Data leakage can occur when information from the testing set is inadvertently used during the imputation process. This can lead to overfitting and unrealistic evaluation results because the imputation is informed by the target variable in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "278e0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputer = IterativeImputer(max_iter=100)\n",
    "imputer_class = MissForest\n",
    "\n",
    "# model_class = RandomForestClassifier\n",
    "# model = LogisticRegression(max_iter=10000)\n",
    "# model_class = svm.SVC\n",
    "model_class = tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a9783059",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[:,:3], y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13b7f830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:400: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-5ee822d00888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Making predictions on the training and testing sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \"\"\"\n\u001b[0;32m    504\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m             if issparse(X) and (\n\u001b[0;32m    473\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m             _assert_all_finite(\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m                     \u001b[1;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                 )\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nDecisionTreeClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Impute data before splitting it into train and test\n",
    "\n",
    "imputer = imputer_class()\n",
    "model = model_class()\n",
    "\n",
    "imputed_data = imputer.fit_transform(X_train)\n",
    "\n",
    "# # Splitting the imputed data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(imputed_data,\n",
    "#                                                     labels,\n",
    "#                                                     test_size=0.3,\n",
    "#                                                     stratify=labels)\n",
    "\n",
    "\n",
    "# Creating and training the model (using Logistic Regression as an example)\n",
    "\n",
    "\n",
    "model.fit(imputed_data, y_train)\n",
    "\n",
    "\n",
    "# Making predictions on the training and testing sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculating accuracy scores\n",
    "# train_accuracy = accuracy_score(y_train.values, y_train_pred)\n",
    "# test_accuracy = accuracy_score(y_test.values, y_test_pred)\n",
    "ret_test = eval_model(y_test, y_test_pred)\n",
    "ret_train = eval_model(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "\n",
    "df_results_test = pd.DataFrame(y_test, columns={'GT'})\n",
    "df_results_test['predicted'] = y_test_pred\n",
    "df_results_test['correct'] = df_results_test['GT'] == df_results_test['predicted']\n",
    "print(df_results_test)\n",
    "\n",
    "\n",
    "print('Test')\n",
    "[print(f'{metric}:{values}') for metric, values in ret_test.items()]\n",
    "print('Train')\n",
    "[print(f'{metric}:{values}') for metric, values in ret_train.items()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae68078",
   "metadata": {},
   "source": [
    "### Imputing the data after each splitting\n",
    "\n",
    "The imputaion quality drops when performing on smaller sub sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250a9dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600cd62d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Splitting the imputed data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.3,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "imputer = imputer_class()\n",
    "model = model_class()\n",
    "\n",
    "imputed_data_train = imputer.fit_transform(X_train)\n",
    "imputed_data_test = imputer.fit_transform(X_test)\n",
    "\n",
    "# Converting the imputed data back to a DataFrame\n",
    "imputed_data_train = pd.DataFrame(imputed_data_train, columns=X_train.columns)\n",
    "imputed_data_test = pd.DataFrame(imputed_data_test, columns=X_test.columns)\n",
    "\n",
    "\n",
    "\n",
    "# Creating and training the model (using Logistic Regression as an example)\n",
    "# model = LogisticRegression()\n",
    "model.fit(imputed_data_train, y_train)\n",
    "\n",
    "# Making predictions on the training and testing sets\n",
    "y_train_pred = model.predict(imputed_data_train)\n",
    "y_test_pred = model.predict(imputed_data_test)\n",
    "\n",
    "# Calculating accuracy scores\n",
    "# train_accuracy = accuracy_score(y_train.values, y_train_pred)\n",
    "# test_accuracy = accuracy_score(y_test.values, y_test_pred)\n",
    "ret_test = eval_model(y_test, y_test_pred)\n",
    "ret_train = eval_model(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "df_results_test = pd.DataFrame(y_test, columns={'GT'})\n",
    "df_results_test['predicted'] = y_test_pred\n",
    "df_results_test['correct'] = df_results_test['GT'] == df_results_test['predicted']\n",
    "print(df_results_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Test')\n",
    "[print(f'{metric}:{values}') for metric, values in ret_test.items()]\n",
    "print('Train')\n",
    "[print(f'{metric}:{values}') for metric, values in ret_train.items()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e3cef",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "Since the data plitting have significant effect on the model performance, cross validation is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_fold(X_train, X_test, y_train, y_test):\n",
    "        # Splitting the imputed data into training and testing sets\n",
    "\n",
    "\n",
    "    imputer = imputer_class(max_iter=500)\n",
    "    model = model_class()\n",
    "    \n",
    "    imputed_data_train = imputer.fit_transform(X_train)\n",
    "    imputed_data_test = imputer.fit_transform(X_test)\n",
    "\n",
    "    # Converting the imputed data back to a DataFrame\n",
    "#     imputed_data_train = pd.DataFrame(imputed_data_train, columns=X_train.columns)\n",
    "#     imputed_data_test = pd.DataFrame(imputed_data_test, columns=X_test.columns)\n",
    "    \n",
    "    # debug\n",
    "#     print(imputed_data_test.shape)\n",
    "#     print(imputed_data_test.shape)\n",
    "\n",
    "\n",
    "    # Creating and training the model (using Logistic Regression as an example)\n",
    "    \n",
    "    model.fit(imputed_data_train, y_train)\n",
    "\n",
    "    # Making predictions on the training and testing sets\n",
    "    y_train_pred = model.predict(imputed_data_train)\n",
    "    y_test_pred = model.predict(imputed_data_test)\n",
    "    \n",
    "    return y_train, y_train_pred, y_test, y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e56b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c3c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=3, shuffle=True)\n",
    "# cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "cv_scores_train = []\n",
    "cv_scores_test = []\n",
    "# for train_index, test_index in cv.split(data, rat_numbers):\n",
    "for train_index, test_index in cv.split(data):\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    y_train, y_train_pred, y_test, y_test_pred = one_fold(X_train, X_test, y_train, y_test)\n",
    "    scores_train = eval_model(y_train, y_train_pred)\n",
    "    scores_test = eval_model(y_test, y_test_pred)\n",
    "    cv_scores_train.append(scores_train)\n",
    "    cv_scores_test.append(scores_test)\n",
    "# Summarize\n",
    "ret_train = pd.DataFrame(cv_scores_train).mean()\n",
    "ret_test = pd.DataFrame(cv_scores_test).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b013f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test')\n",
    "print(ret_test)\n",
    "\n",
    "print('Train')\n",
    "print(ret_train)\n",
    "\n",
    "# print('Test')\n",
    "# [[print(f'{metric}:{values}') for metric, values in ret.items()] for ret in cv_scores_test]\n",
    "# print('Train')\n",
    "# [[print(f'{metric}:{values}') for metric, values in ret.items()] for ret in cv_scores_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c461ad",
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.DataFrame(cv_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553787b7",
   "metadata": {},
   "source": [
    "### Impute the data and see how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe0ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputer = imputer_class(1000)\n",
    "imputed_data = imputer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8314c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_num = np.array(labels=='affiliative', dtype=float)*0.1\n",
    "labels_num = labels_num[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_conc = np.concatenate((data.values, labels_num), axis=1)\n",
    "plt.imshow(data_conc, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data_concat = np.concatenate((imputed_data, labels_num), axis=1)\n",
    "plt.imshow(imputed_data_concat, cmap='hot', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996fe44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X = imputed_data\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=15).fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7b900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "strings = filenames\n",
    "label_encoder = LabelEncoder()\n",
    "converted_numbers = label_encoder.fit_transform(strings)\n",
    "\n",
    "strings = filenames\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "converted_numbers\n",
    "\n",
    "\n",
    "rat_numbers = [extract_ratnum_from_file_name(filename) for filename in filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne = pd.DataFrame(X_embedded)\n",
    "\n",
    "df_tsne['labels'] = labels\n",
    "df_tsne['filenames'] = converted_numbers\n",
    "df_tsne['rat_number'] = rat_numbers\n",
    "# df_tsne['pred'] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72180729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dummies and store it in a variable\n",
    "dummies = pd.get_dummies(df_tsne.labels)\n",
    " \n",
    "# Concatenate the dummies to original dataframe\n",
    "merged = pd.concat([df_tsne, dummies], axis='columns')\n",
    " \n",
    "# drop the values\n",
    "merged.drop(['labels'], axis='columns')\n",
    "\n",
    "merged = merged[['rat_number','affiliative','aversive']].groupby('rat_number').sum()\n",
    "merged['sum'] = merged['affiliative'] + merged['aversive']\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c70675",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_tsne, x=0, y=1, hue='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5013d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.catplot(data=df_tsne, x=0, y=1, hue='rat_number', row='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d216b27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.catplot(data=df_tsne, x=0, y=1, hue='filenames', row='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac03970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548ec31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "all_pos = {}\n",
    "colors = []\n",
    "for r, df_r in df_tsne.groupby('rat_number'):\n",
    "\n",
    "\n",
    "    f_names = df_r['filenames'].values\n",
    "    pos_ = df_r[[0,1]].values\n",
    "    pos_2 = {(r,f): p for p, f in zip(pos_,f_names)}\n",
    "    mean_pos = np.mean(pos_,axis=0)\n",
    "    pos_2[r] = mean_pos\n",
    "    \n",
    "    labels_sub = np.array(['b']* len(df_r))\n",
    "    labels_sub[np.where(np.array(df_r['labels']=='affiliative'))] = 'g'\n",
    "    \n",
    "    all_pos.update(pos_2)\n",
    "    [G.add_edge(r, (r,f)) for f in f_names]\n",
    "    colors = np.append(colors, labels_sub)\n",
    "# colors = np.array(colors).flatten()\n",
    "fig = plt.figure(figsize=(40,80))\n",
    "# nx.draw_networkx(G,all_pos)\n",
    "nx.draw_networkx(G,all_pos, edge_color=colors, font_size=50,width=5)\n",
    "ax = plt.gca()\n",
    "ax.margins(0.08)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d63fbef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# G = nx.Graph()\n",
    "# all_pos = {}\n",
    "# df_g = df_tsne.groupby('rat_number')\n",
    "# n_groups = len(df_g)\n",
    "# fig = plt.figure(figsize=(40,80))\n",
    "# for n, (r, df_r) in enumerate(df_g):\n",
    "#     G = nx.Graph()\n",
    "#     plt.subplot(n_groups,1,n+1)\n",
    "\n",
    "#     f_names = df_r['filenames'].values\n",
    "#     pos_ = df_r[[0,1]].values\n",
    "#     labels_sub = np.array(['b']* len(df_r))\n",
    "#     labels_sub[np.where(np.array(df_r['labels']=='affiliative'))] = 'g'\n",
    "# #     labels_sub = np.append(labels_sub, 'y', axis=None)\n",
    "    \n",
    "    \n",
    "#     pos_2 = {(r,f): p for p, f in zip(pos_,f_names)}\n",
    "#     mean_pos = np.mean(pos_,axis=0)\n",
    "    \n",
    "#     pos_2[r] = mean_pos\n",
    "    \n",
    "#     all_pos.update(pos_2)\n",
    "#     [G.add_edge(r, (r,f)) for f in f_names]\n",
    "    \n",
    "\n",
    "#     nx.draw_networkx(G,pos_2, node_size=2000, font_size=50, edge_color=labels_sub)\n",
    "#     ax = plt.gca()\n",
    "#     ax.margins(0.08)\n",
    "# #     plt.axis(\"off\")\n",
    "#     plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
